# Environment configuration for local RAG tools
#
# Notes
# - Edit values on the right of '=' only; keys are read by the apps.
# - Paths can be relative to project root.
# - Restart your app or shell after changes for them to take effect.

# ChromaDB storage path (persistent vector store)
CHROMA_DIR=./data/chroma

# Embedding model (served by Ollama) and its endpoint
EMBED_MODEL=nomic-embed-text
OLLAMA_URL=http://127.0.0.1:11434

# LLM served by Ollama for answer generation
LLM_MODEL=gemma:2b

# PDF chunking parameters for ingestion (in words)
CHUNK_SIZE=400
CHUNK_OVERLAP=100

# Retrieval settings
TOP_K=4
MIN_SCORE=0.25

# Generation settings
NUM_PREDICT=350
TEMPERATURE=0.2
ANSWER_TIMEOUT=600
STREAM_OUTPUT=true
